# Render Pipeline Language

## Definition

Render pipeline language is GPU programming language which is being developed specifically for Kan project.
It aims to fully represent GPU pipelines and provide enough information to construct pipeline state object right away.
Currently, it is in early prototype stage.

## Goals

- To provide enough information for constructing pipeline stage objects right away without requiring any additional
  context. Having all the information in pipeline file is one of the solutions to PSO hiccup issue.

- To provide enough usable information to build outer high-level objects like materials. For example, pipeline should
  provide information about all attribute-driven and uniform-driven parameters that can be specified through material.

- To reduce amount of hardcode between CPU code and GPU code: there should be no hardcoded locations and bindings.
  Instead, CPU code should rely on provided metadata including parameter tags.

- To reduce amount of time needed to compile uber shader variants by getting rid of preprocessing at all. It is common
  practice to have one shader with lots of macros and then compiling it like 5000 times with different defines. In this
  case the same code is getting parsed repeatedly which is not effective.

## Principles

- Pipelines are able to declare options: values that can be set after parsing and before compilation in order to
  customize pipeline.

- Conditionals are compile-time expressions that only operate on options and are used to customize pipeline without
  preprocessing step.

- Pipeline settings are declared in global scope to express information needed to configure pipeline creation.

- Input data is grouped according to logical blocks that are sources for this data. For example, attributes are no
  longer just a detached variables with input semantic and locations: they're grouped into vertex and instanced 
  attribute containers which makes it possible to properly cover pipeline attribute source configuration.

- All structure, container and buffer fields might contain attached meta tags that can be used by outer logic to bind 
  its data like joint matrices to concrete buffers and variables without requiring them to be named in some hardcoded 
  way.

- All bindings and locations are autogenerated and cannot be hardcoded in any way.

- Samplers and images are always decoupled as separate objects.

- All settings, attribute sources, buffers, samplers and images can be exported to separate structure during compilation
  than can be serialized and later used for high-level object construction.

- Compilation is split in 3 steps: parse step, resolve step and emit step. Parse step produces intermediate data that
  includes conditionals and can be used to produce multiple variants of uber shader. Resolve step processes options,
  gets rid of compile time expressions and produces target-agnostic intermediate data. Emit step uses resolved data
  to construct pipeline metadata and/or emit code in specific language, like SPIRV.

## Options

Options are used to specify how different pipelines variants can be configured in more precise and strict way than it
is usually done through macros.

Currently, there are 5 types of option data:

- `flag` options are used for boolean type of data, like whether some feature is enabled.
- `uint` options are used for unsigned positive numbers, like maximum size of joint matrices array.
- `sint` options are used for signed numbers.
- `float` options are used for floating point numbers.
- `enum` options are used to declare enumeration of option values for user to choose from.

Also, there are 2 classes of options:

- `global` options are allowed to be used everywhere and can be used in any conditional.
  They are primarily used to dictate things that affect input interface of the pipeline.
- `instance` options can only be used in places where they do not affect input interface of the pipeline.

The reason for having two classes is making it easier for the high level code to ensure that several pipelines share
the same input interface and can be classified as a family of the pipelines. It is very useful for materials in 
particular, as we'd like to ensure that all material pipelines for any pass have the same input interface excluding 
pass set input. It can be ensured through setting `global` options for the whole material only and using only
`instance` options for customizing the pass pipelines.

`flag`, `uint`, `sint` and `float` options are declared in global scope and follow the pattern
`option_class <option_name>: option_type <option_value>;` with `true|false` for flag option values.
Keep in mind that `true` and `false` are reserved names and cannot be used for anything other that boolean literals.
For example:

```
global enable_skinning: flag true;
global max_joints: uint 256;
instance wireframe: flag false;
```

`enum` options have a little bit different pattern: 
`option_class <option_name>: enum default_value_string ( other_value_string)+;`. Enum value could be any string.
Declaration example:

```
global skinning_weights: enum "2" "4";
```

Usage example:

```
conditional (enable_skinning && skinning_weights == "2") pack (uint16) u2 joint_indices;
conditional (enable_skinning && skinning_weights == "2") pack (unorm8) f2 joint_weights;

conditional (enable_skinning && skinning_weights == "4") pack (uint16) u4 joint_indices;
conditional (enable_skinning && skinning_weights == "4") pack (unorm8) f4 joint_weights;
```

The main goal of enum options is to restrict the set of possible values that can be passed during compilation to a
subset of string literals.

## Conditional prefixes

Conditional prefixes are used to specify the compile-time condition on which the expression after them is enabled.
Every conditional prefix should be an expression that only uses options and constants and always evaluates to boolean 
value. When conditional prefix is evaluated as `false`, expression after that prefix is excluded from the context.
Below are the examples of conditional prefixes:

```
conditional (!wireframe)
conditional (enable_skinning && skinning_2_weights)
```

## Constants

Constants are scalar values that are used to define global constant values or reuse option-dependant scalar 
calculations. Constant is any expression that can be calculated in compile time, including calculations with options
and other constants like it is done in conditionals. Just like options, constant values can be used in code if they
result in uint, sint or float scalars.

As constants can use other constants and their conditionals can use other constants, constant resolution is a little bit
more complicated than setting resolution. Constants are resolved after options and before settings, but constant 
resolution works in top-down order, meaning that only constants that were declared before can be used to resolve and
calculate next constant.

Below are the examples of constants:

```
constant skinning_2 = enable_skinning && skinning_weights == "2";
constant stencil_none = 0b00000000;
constant stencil_lit_geometry = stencil_bit_has_geometry | stencil_bit_lit;
conditional (use_big_object_buffer) constant object_buffer_size = 1024;
conditional (!use_big_object_buffer) constant object_buffer_size = 64;
```

## Settings

Settings are used to provide information for pipeline configuration. Accepted settings and their types depend on
pipeline type (for example, classic graphics or compute) which is only known to CPU during compilation.

Settings are declared in global scope and follow the pattern: 
`conditional_prefix? setting_name (block unsigned_integer_value)? = setting_value_compile_time_expression;` with
`conditonal_prefix` being allowed to use instance options, `string_name` is an identifier or sequence of identifiers
with `.` between them, optional block suffix for specifying blocks for settings that require block context (for example 
there can be several color outputs, therefore we must specify color output index as block index) and compile time
expression (like expressions in conditionals) for calculating setting value. Setting values can be flags,
unsigned integers, signed integers, floats and strings. Setting type is checked and validated during meta generation
for the pipeline.

Below are the examples of setting declarations in global scope:

```
conditional (!wireframe) setting polygon_mode = "fill";
conditional (wireframe) setting polygon_mode = "wireframe";
setting cull_mode = "back";
setting depth_test = on;
setting depth_write = on;
setting color_output_use_blend block 0 = on;
setting color_output_source_color_blend_factor block 1 = "source_color";
setting stencil_front_reference = 0b00010000;
setting stencil_front_write_mask = 0b11000000 | 0b00000011;
```

We can even use options and constants to calculate settings:

```
instance stencil_any_geometry_mask: uint 0b00000001;
instance stencil_lit_mask: uint 0b00000010;
setting stencil_front_reference = stencil_any_geometry_mask;
setting stencil_front_write_mask = stencil_any_geometry_mask | stencil_lit_mask;
```

## Meta prefixes

Meta prefixes are used to add textual meta tags to struct, container and buffer fields, that can be later used on higher
level to identify required parameters. Meta prefixes follow the pattern: `meta \( tag (, tag)* \)` with `tag` as any 
C-style identifier. Below are the examples of meta prefixes:

```
meta (hidden, model_joint_matrices)
meta (hidden, projection_view_matrix)
```

## Inbuilt types

There is list of currently supported inbuilt types:

- `f1` -- 32-bit floating point scalar.
- `f2`, `f3` and `f4` -- 2, 3 and 4 dimensional vectors of 32-bit floating point scalars.
- `u1` -- 32-bit unsigned integer scalar.
- `u2`, `u3`, `u4` -- 2, 3 and 4 dimensional vectors of 32-bit unsigned integer scalars.
- `s1` -- 32-bit signed integer scalar.
- `s2`, `s3`, `s4` -- 2, 3 and 4 dimensional vectors of 32-bit signed integer scalars.
- `f3x3`, `f4x4` -- 3x3 and 4x4 column-major matrices of 32-bit floating point scalars.

Keep in mind, that any integer literal without suffix (or with `s` suffix) is treated as `s1` literal. In order to
create `u1` literal, add `u` suffix. It is also possible to provide numeric literal using binary format, 
for example `0b11001100`. Binary literals are always treated as `u1` and are supported both in code and for 
option values.

There are several supported constructor signatures for vectors:

- Combine constructor: combines several vectors or scalars into one vector with the same item type. All vectors
  must have these item type. Total count of items must be equal to the constructed vector size.
  Example: `f4 {1.0, f2 {2.0, 3.0}, 4.0}`
- Convert constructor: converts one vector with one item type to another vector with other item type but same count 
  of items. Example: `f4 {u4 {0u, 1u, 2u, 3u}}`
- Fill constructor: fills all the vector items with one scalar value. Example: `f4 {0.5}`.

There are several supported constructor signatures for matrices:

- Combine constructor: combines several vectors into matrix treating them as columns. All vectors must have the same
  item type and the same size (matrix row count). 
  Example: `f3x3 {f3 {1.0, 0.0, 0.0}, f3 {0.0, 1.0, 0.0}, f3 {0.0, 0.0, 1.0}}`.
- Convert constructor: converts matrix with one item type into the matrix of the same size but with different item type.
  Currently unused as all matrices are floating.
- Crop constructor: crops bigger matrix into smaller matrix by leaving out unneeded elements.
  Example: `f4x4 my_big_matrix = f4x4 {...}; f3x3 my_small_matrix = f3x3 {my_big_matrix};`.

There are two ways to access vector items:

- Single item name can be used to access item directly: `x` for first item, `y` for second, `z` for third, 
  `w` for fourth. Using single item access makes it possible to write into items directly.
- Swizzles can be used to create new vectors based on source vector items. Swizzle is a sequence of item names with
  no more than 4 items in it. For example, `f3 my_vector = f3 {...}; f4 result = my_vector.xyxy;` is the same
  as `f3 my_vector = f3 {...}; f4 result = f4 {my_vector.x, my_vector.y, my_vector.x, my_vector.y};`;
  However, swizzles might be a little bit faster as they usually have designated instruction in shader IR languages.

Matrix columns can be accessed as vectors in the same way as single item access works for vectors.

## Note about inbuilt types precision

It was decided to support only 32-bit types for now, because not all GPUs support 16-bit and 8-bit precision inside
pipeline code: most of them do support, but not all of them. 

GLSL in ES mode goes around it by using the feature called relaxed precision in SPIRV: it means that code tells driver 
that it is possible to use 16-bit calculations in specified places if the driver thinks it is beneficial for the 
performance. If GPU does not support 16-bit calculations, then driver will just ignore relaxed precision instructions.
Precision specifiers in GLSL in OpenGL work the same way: they're just advises, not requirements.

It was decided to postpone relaxed precision integration as we don't yet support devices on which it would be possible 
to see the difference.

## Type usage syntax

Type can be specified using syntax: `type_name ((\[ array_dimension_expression \])+ | ...)?` with type_name being 
inbuilt type name or structure name and array_dimension_expression being a compile-time expression that selects size of
array dimension. `...` can be used instead of array suffix in order to declare runtime-sized array. But keep in mind
that runtime sized arrays are only supported in structures and buffers and always should be the last field.
If type is used for structures or buffers, only `global` options can be used inside expression.
Otherwise, `instance` options are allowed.

Below are the examples of types:

```
f3
joint_data_t
f4x4[max_joints]
f4x4...
```

## Structs

Structs are used to declare complex data structures the same way as it is done in C or GLSL.

Struct declaration syntax is:

```
conditional_prefix? struct <struct_name>
{
    (conditional_prefix? meta_prefix? type <field_name>;)+
};
```

Struct declaration example:

```
conditional (enable_skinning) struct joint_data_t
{
    meta (hidden, model_joint_matrices)
    f4x4[max_joints] model_joints;
};
```

## Containers

Containers are used to represent input or output data groups that have type-specific hardware acceleration and therefore
have additional limitations, which makes it impossible to include them under umbrella of buffers. There are several
types of containers:

- `vertex_attribute_container` provides set of attributes with per vertex rate. Its data is only available in vertex
  stage and is read only. Every `vertex_attribute_container` declares new attribute source for the pipeline with
  data block equal to container content.
- `instanced_attribute_container` serves the same purpose as `vertex_attribute_container`, but is used for attributes
  with per instance rate.
- `state_container` is used to declare variables that are shared between pipeline stages. Classic shaders can have
  unique in and out state on every pipeline stage, but we've decided to limit pipeline to one state layout at all stages
  to avoid duplication and to ensure that inputs and outputs always match.
- `color_output_container` is used to declare color output variables for fragment stage. Can only contain vector fields.

All containers can only have vector and matrix fields, structure fields are not supported. The reason is that containers
are built to represent hardware accelerated stage inputs and outputs and therefore are limited by the count of locations
for inputs and outputs on hardware (usually 16 for attributes and 32 for state). With structures, it would be easy to
introduce lots of unnecessary fields and waste these locations, therefore structures are not supported.

`vertex_attribute_container` and `instanced_attribute_container` support `pack` suffix: attributes are not required
to have the same type as their variables in pipeline code -- it is allowed to specify other formats that will be
converted to pipeline variable format during execution. It makes it possible to pack attributes with lower precision
to save space without requiring non-32-bit precision support from GPU. 

`pack` prefixes follow the pattern `pack \(pack_item_class##pack_item_bits\)`, where `pack_item_class` is one of the 
following:

- `float` is a standard floating type.
- `unorm` is a number in `[0, 1]` range linearly represented by unsigned integer.
- `snorm` is a number in `[-1, 1]` range linearly represented by signed integer.
- `uint` is an unsigned integer number.
- `sint` is a signed integer number.

And `pack_bits` is one of the following:

- `8` bits, not supported for `float` class.
- `16` bits.
- `32` bits, only used to explicitly highlight that attribute has 32-bit precision in source data. 
  Not supported for `unorm` and `snorm` as 32 bit floating point value would not be precise enough for that input.

For example: `pack (unorm8)` informs compiler that all elements of the following vector or matrix field will be encoded
in `unorm` format using 8 bits per item.

When stage can both write to pipeline state and read from it, `state_container` access must be used with abstract `in` 
or `out` field group in order to properly resolve state access. For example: `state.in.uv` or `state.out.color`. There
is no such stages right now, but if we implement geometry stage, we'll need to use this syntax in it. The reason is that
`in` and `out` state access patterns can be different on stages like geometry stage, where we would have an array of
every input state variable (one for each input vertex), but one output for emission, therefore guessing which is which
would be tedious and error-prone.

Container declaration examples:

```
vertex_attribute_container vertex
{
    f3 position;
    pack (snorm16) f3 normal;
    pack (float16) f2 uv;

    conditional (enable_skinning && skinning_2_weights) pack (uint16) u2 joint_indices;
    conditional (enable_skinning && skinning_2_weights) pack (unorm8) f2 joint_weights;

    conditional (enable_skinning && skinning_4_weights) pack (uint16) u4 joint_indices;
    conditional (enable_skinning && skinning_4_weights) pack (unorm8) f4 joint_weights;
};

state_container state
{
    f2 uv;
    f4 color_multiplier;
};
```

## Descriptor sets

There are several inbuilt descriptor sets that correspond to the common usage pattern:

- `set_pass` is advised for data that is passed from render pass like view-projection matrix.
- `set_material` is advised for data that is shared between lots of objects and corresponds to
  high level concept of materials.
- `set_object` is advised for data unique for scene object. For example, object may store its data in its own uniform 
  buffer and update this buffer without changing descriptor set.
- `set_shared` is advised for data that can be shared across multiple objects, but is not global enough to be on 
  material set level. For example, one skeleton or even an array of several skeletons can be shared across multiple
  objects, making instancing possible for them.

Any set keyword inside declaration syntax is called `set_prefix` below.

Hardcoded set names are used to make writing shaders more explicit and easy to understand as render pipeline language
is designed to provide as much information as possible to the high level material system instead of just arbitrary set 
numbers. Also, we have only 4 descriptor sets as it is the minimum guaranteed number of supported sets on modern GPUs.

## Buffers

Buffer is a group variables that serve the same purpose and are usually stored in one physical buffer object.
There are several types of buffers:

- `uniform_buffer` represents a classic uniform buffer object including layout restrictions.
- `read_only_storage_buffer` represents a classic storage buffer which is read-only and has `std430` memory layout.
  The only buffer type that supports runtime sized arrays as tails.
- `push_constant` is a special buffer type used to represent push constant layout.

Push constant layout is represented through buffer, because in low level bytecode like SPIRV access to push constant 
data is usually closer to buffer access than to container access. Therefore, it was decided to wrap push constant
layout as a special buffer that has no set prefix and can only be resolved once per pipeline (multiple buffers can be 
declared, but conditionals should ensure that only one is resolved).

`uniform_buffer` and `push_constant` have special layout requirements on hardware side that are a little bit different.
Therefore, mirroring proper layout on CPU could be quite error-prone and difficult to debug. Therefore, it was decided
to only allow 4-item vectors and 4x4 matrices in these buffers: this ensures absence of padding and makes it easier
for the user to choose what resides where. Of course, due to this requirement user is responsible to properly unpack
data from these variables.

Buffer declaration syntax for `uniform_buffer` and `read_only_storage_buffer` is close to struct declaration syntax:

```
conditional_prefix? set_prefix buffer_type <buffer_name>
{
    (conditional_prefix? meta_prefix? type <field_name>;)+
};
```

Buffer declaration syntax for `push_constant` is close to struct declaration syntax:

```
conditional_prefix? push_constant <buffer_name>
{
    (conditional_prefix? meta_prefix? type <field_name>;)+
};
```

Buffer declaration examples:

```
conditional (!support_instancing) set_material uniform_buffer material
{
    f4 color_multiplier;
};

// For the buffer bellow.
struct grid_t
{
    f1 thickness;
    f1 separator;
};

set_material read_only_storage_buffer grid
{
    grid_t... grids;
};

push_constant push
{
    f4x4 shadow_map_projection_view;
    f4 color;
    f4 direction;
};
```

Buffers that can be bound through sets are exposed in metadata and its fields are exposed as parameters. For parameter 
generation, buffer flattening is used. It means that buffer data is represented as tree and then only tree leaves are 
exposed as parameters, where parameter name is equal to path from tree root to parameter leaf. Runtime sized array 
generate tail parameters if their item type is structure. Also, arrays of structs currently do not participate in 
parameter generation for simplification as it is not needed at the moment.

Information about `push_constant` is only exposed as its size, its fields are not exposed as parameters. It is done
like that, because `push_constant` layout is usually highly coupled to render implementation code and therefore there
is not a lot of sense in exposing its structure in meta.

## Samplers

Samplers are always detached from images and are declared as global variables. Samples declaration syntax is:

```
conditional_prefix set_prefix sampler <sampler_name>;
```

Sampler declaration example:

```
set_material sampler texture_sampler;
```

## Images

Images are declared as global variables and are always separate from samplers. There are several supported image types:

- `image_color_2d` is a usual 2d image that is used to store color data.
- `image_color_3d` is a 3d image with color data.
- `image_color_cube` is a usual cube map with color data.
- `image_color_2d_array` is an arrayed 2d image with color data.
- `image_depth_2d` is a usual 2d image that is used to store depth or depth-stencil data.
- `image_depth_3d` is a 3d image with depth or depth-stencil data.
- `image_depth_cube` is a usual cube map with depth or depth-stencil data.
- `image_depth_2d_array` is an arrayed 2d image with depth or depth-stencil data.

It is allowed to declare arrays of images, however only fixed size one dimension arrays are allowed.
Image declaration example:

```
set_material image_depth_2d[max_shadow_maps] shadow_maps;
set_material image_color_2d_array atlas;
```

There are 2 ways to sample image: `sample` function for usual sampling and `sample_dref` function for sampling depth 
images with depth reference comparison. For all sampling functions the first two arguments are sampler and image,
additional arguments depend on image types.

`sample` function additional arguments are:

- For `sampler_color_2d` and `sampler_depth_2d`: `f2 coordinate`.
- For `sampler_color_3d` and `sampler_depth_3d`: `f3 coordinate`.
- For `sampler_color_cube` and `sampler_depth_cube`: `f3 direction`.
- For `sampler_color_2d_array` and `sampler_depth_cube`: `u1 layer` and `f2 coordinate`.

`sample_dref` function additional arguments are:

- For `sampler_depth_2d`: `f2 coordinate` and `f1 reference`.
- For `sampler_depth_3d`: `f3 coordinate` and `f1 reference`.
- For `sampler_depth_cube`: `f3 direction` and `f1 reference`.
- For `sampler_depth_cube`: `u1 layer`, `f2 coordinate` and `f1 reference`.

Sampler call examples:

```
sample (color_sampler, atlas[2], vertex_output.uv)
sample_dref (depth_sampler, shadow_maps[light.shadow_map_index], projected_coordinate, projected_depth)
```

## Functions

Function declaration syntax is close to C with a few exceptions:

- Function can only return non-array types.
- If function doesn't return anything, `void` should be used instead of return type.
- Functions without arguments must be declared as `<return_type> <function_name> (void)`.
- Every function argument is allowed to have conditional prefix.
- Every function argument must have access class: `in` for constant arguments, `out` for write-only output arguments and
  `in out` for arguments that support both reading and writing into them.

Keep in mind that `in out` and `out` function arguments cannot point to non-function-scope variables 
(buffer or container fields) due to limitations of logical pointing model used by formats like SPIRV.

There is also some additional cases where conditionals can be used in function code:

- Scopes can be conditional, for example:

```
conditional (enable_skinning)
{
    // Logic when skinning is enabled.
}
conditional (!enable_skinning)
{
    // Logic when skinning is disabled.
}
```

- There is a conditional alias syntax for situations where we need to refer to different buffers or variables depending
  on pipeline options:

```
conditional (support_instancing) alias (joints, instance_storage.joint_data.model_joints)
conditional (!support_instancing) alias (joints, uniforms.joint_data.model_joints)
// Below, "joints" can be used as a normal variable name.
// Conditional aliases have the same visiblity as variable inside scope.
```
